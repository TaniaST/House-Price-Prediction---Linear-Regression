---
title: "House Prices Prediction Using Linear Regression"
author: "Tetiana Stroganova"
date: "22/03/2019"
documentclass: report
fontsize: 12pt
output: rmarkdown::github_document
---
```{r echo=FALSE, warning=FALSE, message=FALSE, eval= FALSE}
# To run the code and reproduce the findings, the following packages in R must be installed:
install.packages("devtools")
devtools::install_github("ggobi/ggally")
install.packages("GGally")
install.packages("car")
install.packages("gridExtra")
install.packages("ggplot2")
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# The following libraries must be loaded:
library(GGally)
library(car)
library(gridExtra)
```

## Introduction
The goal of the project is to predict the sale price of houses from house sale advertisements currently in the market, using a linear regression model. 

The data set contains 500 sales with the following parameters:

* elevation: Elevation of the base of the house
* dist_am1: Distance to Amenity 1
* dist_am2: Distance to Amenity 2
* dist_am3: Distance to Amenity 3
* bath: Number of bathrooms
* sqft: Square footage of the house
* parking: Parking type
* precip: Amount of precipitation
* price: Final House Sale Price


## 1. Exploratory analysis
Let's have a look at the summary of the data set:

```{r echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
#loading data
dataprice<-read.csv("housing.csv", header=TRUE)
str(dataprice)

rownames(dataprice)<-seq(1,500)
```
```{r echo=FALSE, warning=FALSE, message=FALSE}
summary(dataprice)
```
We can see that there is an odd observation with a negative figure for precipitation variable. As the precipitation cannot be negative, we need to exclude this line from our data.

```{r echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
dataprice<-dataprice[dataprice$precip>=0,]
```
We can also see that for the number of bathrooms, square footage of house and price variables the maximum values are much higher than the 3rd quantile figures.
Let us visualise these extreme values on the corresponding boxplots:

```{r,fig.align="center", fig.width=14, fig.height=6, fig.cap="Boxplots of explanatory variables", echo=FALSE, warning=FALSE, message=FALSE}
#let us see these extreme values on the corresponding boxplots:
#boxplot - Number of bathrooms
boxpl1<-ggplot(data=dataprice,aes(y=bath))+geom_boxplot(outlier.colour = "red")+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())+
  labs(y="Number of bathrooms")
#boxplot - Square footage of the house
boxpl2<-ggplot(data=dataprice,aes(y=sqft))+geom_boxplot(outlier.colour = "red")+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())+
  labs(y="Square footage of the house")
#boxplot - Price
boxpl3<-ggplot(data=dataprice,aes(y=price))+geom_boxplot(outlier.colour = "red")+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())+
  labs(y="Price")

#visualising boxplots
grid.arrange(boxpl1,boxpl2,boxpl3,nrow=1)
```

Let's now use the pairs plot to visualise the relationship between all the variables and to identify any explanatory variables correlating between them:

```{r,fig.align="center", fig.width=12, fig.height=10, echo=FALSE, warning=FALSE, message=FALSE}
ggpairs(dataprice, lower = list(continuous = wrap("points",alpha = 0.3, color = "blue")), diag = list(continuous = wrap("barDiag", colour = "blue")), upper = list(continuous = wrap("cor", size = 5)))
```

As demonstrated by the pairs plot, all the graphs of explanatory vs. response variables show an odd pattern, there is one point standing very far from the others and there is no visible linear relationship between the explanatory variables and the response one. The pairs graphs confirm the presence of a potential outlier for price, square footage of the house and number of bathrooms parameters. It can be also seen from the graphs that the three explanatory variables reflecting the distance to amenities strongly positively correlate between each other. The square footage of the house positively correlates with the number of the bathrooms, but the pattern seems to be affected by one extreme point. 

## 2. Model diagnostics and outlier detection
Let's start with the most general linear model including all the variables:
```{r echo=FALSE, warning=FALSE, message=FALSE}
pricemodel<-lm(formula=price~.,data=dataprice)

summary(pricemodel)
```
As we can see from the initial model summary, the number of bathrooms and square footage of house variables seem to have a significant relationship with the response, but let's check the assumptions of the model:

```{r,fig.align="center", fig.width=12, fig.height=12, echo=FALSE, warning=FALSE, message=FALSE}
par(mfrow=c(2,2))
plot(pricemodel)
```

* Residuals vs. Fitted - there is one fitted value standing very far from the rest of the points, on the far right part of the graph which creates an odd pattern, the red line which should be roughly horizontal and close to zero, goes steeply down and then up again. This indicates the nonconstancy of the variance, we will probably need to exclude the outlier (if the point is an outlier) or carry out a transformation to fix this.

* Normal Q-Q plot - the 348 row stands out of the main curve, it will probably need to be excluded from the model.

* Scale-Location plot - the Fitted values vs. standardized residuals plot shows the similar pattern to Residuals vs. Fitted plot and confirms that the 348 will probably need to be excluded from the model.

* Cook's distance - finally, the Cook's distance on the Residuals vs. Leverage graph confirms that the row 348 should be excluded.

To confirm our choice of the outlier formally, let's carry out the Bonferroni outliers test:
```{r echo=FALSE, warning=FALSE, message=FALSE}
outlierTest(pricemodel)
```
The test gives us the same result, so the row 348 should be excluded from the data.
```{r echo=FALSE, warning=FALSE, message=FALSE}
dataprice<-dataprice[rownames(dataprice)!="348",]
```
Let's analyse the residuals plots again to see if the removal of the outlier fixed the violations of the assumptions.
```{r,fig.align="center", fig.width=12, fig.height=12, echo=FALSE, warning=FALSE, message=FALSE}
pricemodel<-lm(formula=price~.,data=dataprice)
par(mfrow=c(2,2))
plot(pricemodel)
```

* Residuals vs. Fitted - the removal of the outlier has fixed the problem of nonconstancy in the variance, there is no need for transformation.

* Normal Q-Q plot - the plot shows a short-tailed distribution: the pattern corresponds to the theoretical line in the center, but the points are above the line in the bottom left part and under the line in the top right part. 

* Scale-Location plot - the plot confirms that the variance of the residuals is constant (roughly horizontal red line).

* Cook's distance - the plot shows that there are no outliers in the data.

Let's have a look at the pairs plot again to see if the patterns have changed after the outlier removal.

```{r,fig.align="center", fig.width=12, fig.height=10, echo=FALSE, warning=FALSE, message=FALSE}
ggpairs(dataprice, lower = list(continuous = wrap("points",alpha = 0.3, color = "blue")), diag = list(continuous = wrap("barDiag", colour = "blue")), upper = list(continuous = wrap("cor", size = 5)))
```
As shown by the pairs plot, the removal of the outlier has modified the relationship of the square footage of the house and the number of bathrooms parameters, they are not correlated anymore (the correlation coefficient has decreased from 0.83 to 0.05). The response variable appears to be highly positively correlated with the number of the bathrooms.

## 3. Model Selection
Using the stepwise model selection method (step() function in R), we narrow down the model to two explanatory variables: number of bathrooms and square footage of the house.
```{r echo=FALSE, warning=FALSE, message=FALSE,results="hide"}
model<-step(pricemodel,direction="both")
```
Let's check the residuals plots:
```{r,fig.align="center", fig.width=12, fig.height=12, fig.cap="Residuals plots", echo=FALSE, warning=FALSE, message=FALSE}
par(mfrow=c(2,2))
plot(model)
```

* Residuals vs. Fitted - there is no problem of nonconstancy in the variance, the red line is roughly horizontal
* Normal Q-Q plot - the plot shows a short-tailed distribution with good fit for the majority of the points and more distant points on the tails. As the consequences of non-normality for short-tailed distributions are not serious, they can be ignored.

* Scale-Location plot - it confirms that there is no major problem with nonconstance of the variance (roughly horizontal red line).

* Residuals vs. Leverage plot - it indicates that there are no outliers in the model.

Let's now check the significance of the explanatory variables, using the model summary:
```{r echo=FALSE, warning=FALSE, message=FALSE}
summary(model)
```
From the summary output, we can see that the p-value for the square footage of the house variable is more than 0.05 (0.1424). This indicates that the relationship between this variable and the response is not significant.

Before concluding anything, let's check the confidence intervals:
```{r echo=FALSE, warning=FALSE, message=FALSE}
confint(model)
```
The confidence interval for the number of bathrooms variable does not contain 0 (169095,181661), so the relationship between this explanatory variable and the response is significant. However, the confidence interval for the square footage of the house variable contains 0 (-3.99,27.7), so the relationship between this variable and the price is not significant. We need to drop this variable, but let's check the single models first.

#### Single model - number of bathrooms vs. price
```{r echo=FALSE, warning=FALSE, message=FALSE}
summary(lm(formula=price~bath,data=dataprice))
confint(lm(formula=price~bath,data=dataprice))
```
Both summary and confidence interval outputs confirm the significant relationship between the number of bathrooms variable alone and price, as p-value is less than 0.05 and the confidence interval doesn't contain 0 (169355,181916)

#### Single model - square footage of the house vs. price
```{r echo=FALSE, warning=FALSE, message=FALSE}
summary(lm(formula=price~sqft,data=dataprice))
confint(lm(formula=price~sqft,data=dataprice))
```
The square footage of the house variable alone shows no significant relationship with price, as we can see from both confidence interval which contains 0 (-5.96,78.01) and summary output where p-value is greater than 0.05. As both the outcome of the confidence interval and of the model summary suggest, the square footage of the house variable does not have a significant relationship with the price. 

Let's check the adjusted R squared coefficient of the model before dropping the square footage of the house variable and after:
```{r echo=FALSE, warning=FALSE, message=FALSE}
finalmodel<-lm(price~bath,data=dataprice)
summary(model)
summary(finalmodel)
```
The adj. R squared is 0.8589 for the model before dropping the square footage of the house variable and 0.8586 after the drop. There is no major change in adj. R squared coefficient, so we retain only one variable - the number of the bathrooms. Let's check the assumptions again to ensure there are no violations:
```{r echo=FALSE, warning=FALSE, message=FALSE, fig.align="center", fig.width=12, fig.height=12}
par(mfrow=c(2,2))
plot(finalmodel)
```

* Residuals vs. Fitted - no problem of nonconstant variance

* Normal Q-Q plot - again a short-tailed distribution with good fit for the majority of the points and more distant points on the tails.

* The Scale-Location plot - no problems with nonconstance of the variance.

* Residuals vs. Leverage plot - no outliers in the model.

## 4. Conclusions
The analysis of the data has shown that the number of bathrooms is the only variable explaining the variability of the price. Even if initially the square footage of the house was included in the model, the confidence intervals check revealed the insignificance of the relationship. The final model explains 85.86% of variability of the house price and shows that for every one unit increase in the number of bathrooms, the price increases by 175635 units on average.

In the above analysis the number of bathrooms variable has been treated as numerical, another approach would be to include it in the model as factor with 4 levels and explore the models with different regression lines, with parallel regression lines and with a single regression line (with no difference among the groups).

